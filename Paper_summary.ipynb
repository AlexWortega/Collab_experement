{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Paper_summary.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "C9qehmLWJcZ9",
        "WeII7tchJbnp"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexWortega/Collab_experement/blob/main/Paper_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvkkKT4qVfM2"
      },
      "source": [
        "#Research paper summary\r\n",
        "* Запустите последовательно первые две ячейки\r\n",
        "* Замените None на линку на .pdf файл \r\n",
        "* По идее все должно работать\r\n",
        "-------\r\n",
        "##todo\r\n",
        "* парсить формулы и выводить отдельно\r\n",
        "* вывод в виде .pdf\r\n",
        "* узнать почему пдф парсер выдает какие то ключи "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9qehmLWJcZ9"
      },
      "source": [
        "#Инсталятор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXu_yLgiJJDk"
      },
      "source": [
        "pip install bert-extractive-summarizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQSU2LB2Jber"
      },
      "source": [
        "pip install spacy==2.1.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkYfMht0JmVx"
      },
      "source": [
        "pip install transformers==2.2.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_UUMU7BJpNv"
      },
      "source": [
        "pip install neuralcoref"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjuKXrc4RVgh"
      },
      "source": [
        "pip install nameparser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ats6g6SZJsTW"
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKi5hz_PJ4aj"
      },
      "source": [
        "pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXb46ekELALW"
      },
      "source": [
        "pip install tika"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6SeLstGNMkX"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "nltk.download('maxent_ne_chunker')\r\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeII7tchJbnp"
      },
      "source": [
        "#какой то код\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBcESM4-Kfv9"
      },
      "source": [
        "import wget\r\n",
        "import nltk\r\n",
        "from nameparser.parser import HumanName\r\n",
        "from nltk.corpus import wordnet\r\n",
        "from summarizer import Summarizer\r\n",
        "import re\r\n",
        "\r\n",
        "filer = None\r\n",
        "def file_loader(url):\r\n",
        "    try:\r\n",
        "      wget.download(url, 'paper.pdf')\r\n",
        "      print('succsessfuly download .pdf from '+url)\r\n",
        "    except:\r\n",
        "      print('something wents wrong')\r\n",
        "\r\n",
        "\r\n",
        "def urlsfrompaper(text):\r\n",
        "    \r\n",
        "    return re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\r\n",
        "\r\n",
        "\r\n",
        "person_list = []\r\n",
        "person_names=person_list\r\n",
        "def get_human_names(text):\r\n",
        "    tokens = nltk.tokenize.word_tokenize(text)\r\n",
        "    pos = nltk.pos_tag(tokens)\r\n",
        "    sentt = nltk.ne_chunk(pos, binary = False)\r\n",
        "\r\n",
        "    person = []\r\n",
        "    name = \"\"\r\n",
        "    for subtree in sentt.subtrees(filter=lambda t: t.label() == 'PERSON'):\r\n",
        "        for leaf in subtree.leaves():\r\n",
        "            person.append(leaf[0])\r\n",
        "        if len(person) > 1: #avoid grabbing lone surnames\r\n",
        "            for part in person:\r\n",
        "                name += part + ' '\r\n",
        "            if name[:-1] not in person_list:\r\n",
        "                person_list.append(name[:-1])\r\n",
        "            name = ''\r\n",
        "        person = []\r\n",
        "    return (person_list)\r\n",
        "\r\n",
        "\r\n",
        "def cleaner(text):\r\n",
        "  names = get_human_names(main_text)+urlsfrompaper(main_text)+ ['pages','arxiv','2016','2017','2018']\r\n",
        "  for name in names:\r\n",
        "    text = text.replace(name,'')\r\n",
        "  return text\r\n",
        "\r\n",
        "def summarizer(main_text):\r\n",
        "  \r\n",
        "  model = Summarizer()\r\n",
        "  result = model(main_text, min_length=100)\r\n",
        "  full = ''.join(result)\r\n",
        "  return full\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRb32XC1T9KG"
      },
      "source": [
        "#Вставте линку и запустите ячейку ниже"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEi5f5HLO0Sf"
      },
      "source": [
        "#@title String fields\r\n",
        "\r\n",
        "link = 'https://arxiv.org/pdf/2008.08995.pdf' #@param {type:\"string\"}\r\n",
        "\r\n",
        "from tika import parser\r\n",
        "\r\n",
        "url = 'https://arxiv.org/pdf/2008.08995.pdf'\r\n",
        "file_loader(link)\r\n",
        "raw = parser.from_file('cat4.pdf')\r\n",
        "main_text = cleaner(raw['content'])\r\n",
        "\r\n",
        "print(summarizer(main_text))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}